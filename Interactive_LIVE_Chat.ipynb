{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fat-ai/EasyAnimate/blob/main/Interactive_LIVE_Chat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGULEYsogPjJ"
      },
      "source": [
        "OUTSTANDING ISSUES\n",
        "- MOBILE - add to homescreen instructions\n",
        "- MULTIPLE USERS\n",
        "- SPEED\n",
        "- CONTROL MIC SENSITIVITY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "w3QgO8q3j5vq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11b98546-7e17-4697-af8c-d79c0b0c93ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#@title Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FB6K9cvkIg_",
        "outputId": "b0cc5def-846a-49f9-f6a8-e2e91f984fcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing reqs.txt\n"
          ]
        }
      ],
      "source": [
        "#@title Prepare Installation\n",
        "%%writefile reqs.txt\n",
        "langchain_groq\n",
        "transformers\n",
        "torch\n",
        "TTS\n",
        "gradio\n",
        "wave\n",
        "pyannote-audio\n",
        "https://github.com/marianne-m/brouhaha-vad/archive/main.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-1YbioDlHAK",
        "outputId": "4d3618c0-f5e2-4385-a04c-0f31b96ccab7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K       \u001b[32m-\u001b[0m \u001b[32m49.0 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m \u001b[33m0:00:05\u001b[0m\n",
            "\u001b[?25h    Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h    Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m99.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h    Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h    Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h    Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h    Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m103.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h    Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h    Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h    Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h    Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h    Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h    Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h    Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m121.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.2/797.2 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m107.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m938.0/938.0 kB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m96.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m97.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.6/318.6 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m873.5/873.5 kB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m97.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.5/103.5 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.5/417.5 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m379.9/379.9 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.9/252.9 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m808.5/808.5 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.3/143.3 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m103.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m101.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.9/423.9 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.3/119.3 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m705.5/705.5 kB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.5/776.5 kB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m113.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m435.5/435.5 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m108.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m760.1/760.1 kB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m114.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m97.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m866.2/866.2 kB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.2/51.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.4/121.4 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m833.7/833.7 kB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m111.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.0/163.0 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.9/443.9 kB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.1/142.1 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.2/305.2 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.8/293.8 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m107.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.0/182.0 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.2/140.2 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.1/385.1 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.6/64.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.9/156.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.0/493.0 kB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m922.4/922.4 kB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 kB\u001b[0m \u001b[31m152.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.3/227.3 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.6/301.6 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m88.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.5/290.5 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.3/812.3 kB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.0/233.0 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m112.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m94.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m108.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.8/117.8 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m96.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m114.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.6/117.6 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m616.0/616.0 kB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.7/526.7 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: --strip-extras is becoming the default in version 8.0.0. To silence this warning, either use --strip-extras to opt into the new default or use --no-strip-extras to retain the existing behavior.\u001b[0m\n",
            "\u001b[32m#\u001b[0m\u001b[0m\n",
            "\u001b[32m# This file is autogenerated by pip-compile with Python 3.10\u001b[0m\u001b[0m\n",
            "\u001b[32m# by the following command:\u001b[0m\u001b[0m\n",
            "\u001b[32m#\u001b[0m\u001b[0m\n",
            "\u001b[32m#    pip-compile --output-file=requirements.txt /content/reqs.txt\u001b[0m\u001b[0m\n",
            "\u001b[32m#\u001b[0m\u001b[0m\n",
            "absl-py==2.1.0\n",
            "    \u001b[32m# via tensorboard\u001b[0m\u001b[0m\n",
            "aiofiles==23.2.1\n",
            "    \u001b[32m# via gradio\u001b[0m\u001b[0m\n",
            "aiohappyeyeballs==2.3.4\n",
            "    \u001b[32m# via aiohttp\u001b[0m\u001b[0m\n",
            "aiohttp==3.10.1\n",
            "    \u001b[32m# via\n",
            "    #   fsspec\n",
            "    #   tts\u001b[0m\u001b[0m\n",
            "aiosignal==1.3.1\n",
            "    \u001b[32m# via aiohttp\u001b[0m\u001b[0m\n",
            "alembic==1.13.2\n",
            "    \u001b[32m# via optuna\u001b[0m\u001b[0m\n",
            "annotated-types==0.7.0\n",
            "    \u001b[32m# via pydantic\u001b[0m\u001b[0m\n",
            "antlr4-python3-runtime==4.9.3\n",
            "    \u001b[32m# via omegaconf\u001b[0m\u001b[0m\n",
            "anyascii==0.3.2\n",
            "    \u001b[32m# via tts\u001b[0m\u001b[0m\n",
            "anyio==4.4.0\n",
            "    \u001b[32m# via\n",
            "    #   gradio\n",
            "    #   groq\n",
            "    #   httpx\n",
            "    #   starlette\u001b[0m\u001b[0m\n",
            "asteroid-filterbanks==0.4.0\n",
            "    \u001b[32m# via pyannote-audio\u001b[0m\u001b[0m\n",
            "async-timeout==4.0.3\n",
            "    \u001b[32m# via aiohttp\u001b[0m\u001b[0m\n",
            "attrs==24.1.0\n",
            "    \u001b[32m# via aiohttp\u001b[0m\u001b[0m\n",
            "audioread==3.0.1\n",
            "    \u001b[32m# via librosa\u001b[0m\u001b[0m\n",
            "babel==2.15.0\n",
            "    \u001b[32m# via gruut\u001b[0m\u001b[0m\n",
            "bangla==0.0.2\n",
            "    \u001b[32m# via tts\u001b[0m\u001b[0m\n",
            "blinker==1.8.2\n",
            "    \u001b[32m# via flask\u001b[0m\u001b[0m\n",
            "blis==0.7.11\n",
            "    \u001b[32m# via thinc\u001b[0m\u001b[0m\n",
            "bnnumerizer==0.0.2\n",
            "    \u001b[32m# via tts\u001b[0m\u001b[0m\n",
            "bnunicodenormalizer==0.1.7\n",
            "    \u001b[32m# via tts\u001b[0m\u001b[0m\n",
            "brouhaha @ https://github.com/marianne-m/brouhaha-vad/archive/main.zip\n",
            "    \u001b[32m# via -r /content/reqs.txt\u001b[0m\u001b[0m\n",
            "catalogue==2.0.10\n",
            "    \u001b[32m# via\n",
            "    #   spacy\n",
            "    #   srsly\n",
            "    #   thinc\u001b[0m\u001b[0m\n",
            "certifi==2024.7.4\n",
            "    \u001b[32m# via\n",
            "    #   httpcore\n",
            "    #   httpx\n",
            "    #   requests\u001b[0m\u001b[0m\n",
            "cffi==1.16.0\n",
            "    \u001b[32m# via soundfile\u001b[0m\u001b[0m\n",
            "charset-normalizer==3.3.2\n",
            "    \u001b[32m# via requests\u001b[0m\u001b[0m\n",
            "click==8.1.7\n",
            "    \u001b[32m# via\n",
            "    #   flask\n",
            "    #   nltk\n",
            "    #   typer\n",
            "    #   uvicorn\u001b[0m\u001b[0m\n",
            "cloudpathlib==0.18.1\n",
            "    \u001b[32m# via weasel\u001b[0m\u001b[0m\n",
            "colorlog==6.8.2\n",
            "    \u001b[32m# via optuna\u001b[0m\u001b[0m\n",
            "confection==0.1.5\n",
            "    \u001b[32m# via\n",
            "    #   thinc\n",
            "    #   weasel\u001b[0m\u001b[0m\n",
            "contourpy==1.2.1\n",
            "    \u001b[32m# via matplotlib\u001b[0m\u001b[0m\n",
            "coqpit==0.0.17\n",
            "    \u001b[32m# via\n",
            "    #   trainer\n",
            "    #   tts\u001b[0m\u001b[0m\n",
            "cycler==0.12.1\n",
            "    \u001b[32m# via matplotlib\u001b[0m\u001b[0m\n",
            "cymem==2.0.8\n",
            "    \u001b[32m# via\n",
            "    #   preshed\n",
            "    #   spacy\n",
            "    #   thinc\u001b[0m\u001b[0m\n",
            "cython==3.0.11\n",
            "    \u001b[32m# via tts\u001b[0m\u001b[0m\n",
            "dateparser==1.1.8\n",
            "    \u001b[32m# via gruut\u001b[0m\u001b[0m\n",
            "decorator==5.1.1\n",
            "    \u001b[32m# via librosa\u001b[0m\u001b[0m\n",
            "distro==1.9.0\n",
            "    \u001b[32m# via groq\u001b[0m\u001b[0m\n",
            "docopt==0.6.2\n",
            "    \u001b[32m# via\n",
            "    #   num2words\n",
            "    #   pyannote-metrics\n",
            "    #   pyannote-pipeline\u001b[0m\u001b[0m\n",
            "einops==0.8.0\n",
            "    \u001b[32m# via\n",
            "    #   encodec\n",
            "    #   pyannote-audio\n",
            "    #   tts\u001b[0m\u001b[0m\n",
            "encodec==0.1.1\n",
            "    \u001b[32m# via tts\u001b[0m\u001b[0m\n",
            "exceptiongroup==1.2.2\n",
            "    \u001b[32m# via anyio\u001b[0m\u001b[0m\n",
            "fastapi==0.112.0\n",
            "    \u001b[32m# via gradio\u001b[0m\u001b[0m\n",
            "ffmpy==0.4.0\n",
            "    \u001b[32m# via gradio\u001b[0m\u001b[0m\n",
            "filelock==3.15.4\n",
            "    \u001b[32m# via\n",
            "    #   huggingface-hub\n",
            "    #   pyannote-pipeline\n",
            "    #   torch\n",
            "    #   transformers\n",
            "    #   triton\u001b[0m\u001b[0m\n",
            "flask==3.0.3\n",
            "    \u001b[32m# via tts\u001b[0m\u001b[0m\n",
            "fonttools==4.53.1\n",
            "    \u001b[32m# via matplotlib\u001b[0m\u001b[0m\n",
            "frozenlist==1.4.1\n",
            "    \u001b[32m# via\n",
            "    #   aiohttp\n",
            "    #   aiosignal\u001b[0m\u001b[0m\n",
            "fsspec[http]==2024.6.1\n",
            "    \u001b[32m# via\n",
            "    #   gradio-client\n",
            "    #   huggingface-hub\n",
            "    #   lightning\n",
            "    #   pytorch-lightning\n",
            "    #   torch\n",
            "    #   trainer\n",
            "    #   tts\u001b[0m\u001b[0m\n",
            "g2pkk==0.1.2\n",
            "    \u001b[32m# via tts\u001b[0m\u001b[0m\n",
            "gradio==4.40.0\n",
            "    \u001b[32m# via -r /content/reqs.txt\u001b[0m\u001b[0m\n",
            "gradio-client==1.2.0\n",
            "    \u001b[32m# via gradio\u001b[0m\u001b[0m\n",
            "greenlet==3.0.3\n",
            "    \u001b[32m# via sqlalchemy\u001b[0m\u001b[0m\n",
            "groq==0.9.0\n",
            "    \u001b[32m# via langchain-groq\u001b[0m\u001b[0m\n",
            "grpcio==1.65.4\n",
            "    \u001b[32m# via tensorboard\u001b[0m\u001b[0m\n",
            "gruut[de,es,fr]==2.2.3\n",
            "    \u001b[32m# via tts\u001b[0m\u001b[0m\n",
            "gruut-ipa==0.13.0\n",
            "    \u001b[32m# via gruut\u001b[0m\u001b[0m\n",
            "gruut-lang-de==2.0.1\n",
            "    \u001b[32m# via gruut\u001b[0m\u001b[0m\n",
            "gruut-lang-en==2.0.1\n",
            "    \u001b[32m# via gruut\u001b[0m\u001b[0m\n",
            "gruut-lang-es==2.0.1\n",
            "    \u001b[32m# via gruut\u001b[0m\u001b[0m\n",
            "gruut-lang-fr==2.0.2\n",
            "    \u001b[32m# via gruut\u001b[0m\u001b[0m\n",
            "h11==0.14.0\n",
            "    \u001b[32m# via\n",
            "    #   httpcore\n",
            "    #   uvicorn\u001b[0m\u001b[0m\n",
            "hangul-romanize==0.1.0\n",
            "    \u001b[32m# via tts\u001b[0m\u001b[0m\n",
            "httpcore==1.0.5\n",
            "    \u001b[32m# via httpx\u001b[0m\u001b[0m\n",
            "httpx==0.27.0\n",
            "    \u001b[32m# via\n",
            "    #   gradio\n",
            "    #   gradio-client\n",
            "    #   groq\u001b[0m\u001b[0m\n",
            "huggingface-hub==0.24.5\n",
            "    \u001b[32m# via\n",
            "    #   gradio\n",
            "    #   gradio-client\n",
            "    #   pyannote-audio\n",
            "    #   speechbrain\n",
            "    #   tokenizers\n",
            "    #   transformers\u001b[0m\u001b[0m\n",
            "hyperpyyaml==1.2.2\n",
            "    \u001b[32m# via speechbrain\u001b[0m\u001b[0m\n",
            "idna==3.7\n",
            "    \u001b[32m# via\n",
            "    #   anyio\n",
            "    #   httpx\n",
            "    #   requests\n",
            "    #   yarl\u001b[0m\u001b[0m\n",
            "importlib-resources==6.4.0\n",
            "    \u001b[32m# via gradio\u001b[0m\u001b[0m\n",
            "inflect==7.3.1\n",
            "    \u001b[32m# via tts\u001b[0m\u001b[0m\n",
            "itsdangerous==2.2.0\n",
            "    \u001b[32m# via flask\u001b[0m\u001b[0m\n",
            "jamo==0.4.1\n",
            "    \u001b[32m# via\n",
            "    #   g2pkk\n",
            "    #   tts\u001b[0m\u001b[0m\n",
            "jieba==0.42.1\n",
            "    \u001b[32m# via tts\u001b[0m\u001b[0m\n",
            "jinja2==3.1.4\n",
            "    \u001b[32m# via\n",
            "    #   flask\n",
            "    #   gradio\n",
            "    #   spacy\n",
            "    #   torch\u001b[0m\u001b[0m\n",
            "joblib==1.4.2\n",
            "    \u001b[32m# via\n",
            "    #   librosa\n",
            "    #   nltk\n",
            "    #   pynndescent\n",
            "    #   scikit-learn\n",
            "    #   speechbrain\u001b[0m\u001b[0m\n",
            "jsonlines==1.2.0\n",
            "    \u001b[32m# via gruut\u001b[0m\u001b[0m\n",
            "jsonpatch==1.33\n",
            "    \u001b[32m# via langchain-core\u001b[0m\u001b[0m\n",
            "jsonpointer==3.0.0\n",
            "    \u001b[32m# via jsonpatch\u001b[0m\u001b[0m\n",
            "julius==0.2.7\n",
            "    \u001b[32m# via torch-audiomentations\u001b[0m\u001b[0m\n",
            "kiwisolver==1.4.5\n",
            "    \u001b[32m# via matplotlib\u001b[0m\u001b[0m\n",
            "langchain-core==0.2.28\n",
            "    \u001b[32m# via langchain-groq\u001b[0m\u001b[0m\n",
            "langchain-groq==0.1.9\n",
            "    \u001b[32m# via -r /content/reqs.txt\u001b[0m\u001b[0m\n",
            "langcodes==3.4.0\n",
            "    \u001b[32m# via spacy\u001b[0m\u001b[0m\n",
            "langsmith==0.1.98\n",
            "    \u001b[32m# via langchain-core\u001b[0m\u001b[0m\n",
            "language-data==1.2.0\n",
            "    \u001b[32m# via langcodes\u001b[0m\u001b[0m\n",
            "lazy-loader==0.4\n",
            "    \u001b[32m# via librosa\u001b[0m\u001b[0m\n",
            "librosa==0.10.0\n",
            "    \u001b[32m# via\n",
            "    #   torch-audiomentations\n",
            "    #   tts\u001b[0m\u001b[0m\n",
            "lightning==2.3.3\n",
            "    \u001b[32m# via pyannote-audio\u001b[0m\u001b[0m\n",
            "lightning-utilities==0.11.6\n",
            "    \u001b[32m# via\n",
            "    #   lightning\n",
            "    #   pytorch-lightning\n",
            "    #   torchmetrics\u001b[0m\u001b[0m\n",
            "llvmlite==0.43.0\n",
            "    \u001b[32m# via\n",
            "    #   numba\n",
            "    #   pynndescent\u001b[0m\u001b[0m\n",
            "mako==1.3.5\n",
            "    \u001b[32m# via alembic\u001b[0m\u001b[0m\n",
            "marisa-trie==1.2.0\n",
            "    \u001b[32m# via language-data\u001b[0m\u001b[0m\n",
            "markdown==3.6\n",
            "    \u001b[32m# via tensorboard\u001b[0m\u001b[0m\n",
            "markdown-it-py==3.0.0\n",
            "    \u001b[32m# via rich\u001b[0m\u001b[0m\n",
            "markupsafe==2.1.5\n",
            "    \u001b[32m# via\n",
            "    #   gradio\n",
            "    #   jinja2\n",
            "    #   mako\n",
            "    #   werkzeug\u001b[0m\u001b[0m\n",
            "matplotlib==3.8.4\n",
            "    \u001b[32m# via\n",
            "    #   gradio\n",
            "    #   pyannote-metrics\n",
            "    #   tts\u001b[0m\u001b[0m\n",
            "mdurl==0.1.2\n",
            "    \u001b[32m# via markdown-it-py\u001b[0m\u001b[0m\n",
            "more-itertools==10.3.0\n",
            "    \u001b[32m# via inflect\u001b[0m\u001b[0m\n",
            "mpmath==1.3.0\n",
            "    \u001b[32m# via sympy\u001b[0m\u001b[0m\n",
            "msgpack==1.0.8\n",
            "    \u001b[32m# via librosa\u001b[0m\u001b[0m\n",
            "multidict==6.0.5\n",
            "    \u001b[32m# via\n",
            "    #   aiohttp\n",
            "    #   yarl\u001b[0m\u001b[0m\n",
            "murmurhash==1.0.10\n",
            "    \u001b[32m# via\n",
            "    #   preshed\n",
            "    #   spacy\n",
            "    #   thinc\u001b[0m\u001b[0m\n",
            "networkx==2.8.8\n",
            "    \u001b[32m# via\n",
            "    #   gruut\n",
            "    #   torch\u001b[0m\u001b[0m\n",
            "nltk==3.8.1\n",
            "    \u001b[32m# via\n",
            "    #   g2pkk\n",
            "    #   tts\u001b[0m\u001b[0m\n",
            "num2words==0.5.13\n",
            "    \u001b[32m# via\n",
            "    #   gruut\n",
            "    #   tts\u001b[0m\u001b[0m\n",
            "numba==0.60.0\n",
            "    \u001b[32m# via\n",
            "    #   librosa\n",
            "    #   pynndescent\n",
            "    #   tts\n",
            "    #   umap-learn\u001b[0m\u001b[0m\n",
            "numpy==1.22.0\n",
            "    \u001b[32m# via\n",
            "    #   asteroid-filterbanks\n",
            "    #   blis\n",
            "    #   contourpy\n",
            "    #   encodec\n",
            "    #   gradio\n",
            "    #   gruut\n",
            "    #   librosa\n",
            "    #   lightning\n",
            "    #   matplotlib\n",
            "    #   numba\n",
            "    #   optuna\n",
            "    #   pandas\n",
            "    #   pyannote-core\n",
            "    #   pyannote-metrics\n",
            "    #   pytorch-lightning\n",
            "    #   pytorch-metric-learning\n",
            "    #   scikit-learn\n",
            "    #   scipy\n",
            "    #   soxr\n",
            "    #   spacy\n",
            "    #   speechbrain\n",
            "    #   tensorboard\n",
            "    #   tensorboardx\n",
            "    #   thinc\n",
            "    #   torchmetrics\n",
            "    #   transformers\n",
            "    #   tts\n",
            "    #   umap-learn\u001b[0m\u001b[0m\n",
            "nvidia-cublas-cu12==12.1.3.1\n",
            "    \u001b[32m# via\n",
            "    #   nvidia-cudnn-cu12\n",
            "    #   nvidia-cusolver-cu12\n",
            "    #   torch\u001b[0m\u001b[0m\n",
            "nvidia-cuda-cupti-cu12==12.1.105\n",
            "    \u001b[32m# via torch\u001b[0m\u001b[0m\n",
            "nvidia-cuda-nvrtc-cu12==12.1.105\n",
            "    \u001b[32m# via torch\u001b[0m\u001b[0m\n",
            "nvidia-cuda-runtime-cu12==12.1.105\n",
            "    \u001b[32m# via torch\u001b[0m\u001b[0m\n",
            "nvidia-cudnn-cu12==9.1.0.70\n",
            "    \u001b[32m# via torch\u001b[0m\u001b[0m\n",
            "nvidia-cufft-cu12==11.0.2.54\n",
            "    \u001b[32m# via torch\u001b[0m\u001b[0m\n",
            "nvidia-curand-cu12==10.3.2.106\n",
            "    \u001b[32m# via torch\u001b[0m\u001b[0m\n",
            "nvidia-cusolver-cu12==11.4.5.107\n",
            "    \u001b[32m# via torch\u001b[0m\u001b[0m\n",
            "nvidia-cusparse-cu12==12.1.0.106\n",
            "    \u001b[32m# via\n",
            "    #   nvidia-cusolver-cu12\n",
            "    #   torch\u001b[0m\u001b[0m\n",
            "nvidia-nccl-cu12==2.20.5\n",
            "    \u001b[32m# via torch\u001b[0m\u001b[0m\n",
            "nvidia-nvjitlink-cu12==12.6.20\n",
            "    \u001b[32m# via\n",
            "    #   nvidia-cusolver-cu12\n",
            "    #   nvidia-cusparse-cu12\u001b[0m\u001b[0m\n",
            "nvidia-nvtx-cu12==12.1.105\n",
            "    \u001b[32m# via torch\u001b[0m\u001b[0m\n",
            "omegaconf==2.3.0\n",
            "    \u001b[32m# via pyannote-audio\u001b[0m\u001b[0m\n",
            "optuna==3.6.1\n",
            "    \u001b[32m# via pyannote-pipeline\u001b[0m\u001b[0m\n",
            "orjson==3.10.6\n",
            "    \u001b[32m# via\n",
            "    #   gradio\n",
            "    #   langsmith\u001b[0m\u001b[0m\n",
            "packaging==24.1\n",
            "    \u001b[32m# via\n",
            "    #   gradio\n",
            "    #   gradio-client\n",
            "    #   huggingface-hub\n",
            "    #   langchain-core\n",
            "    #   lazy-loader\n",
            "    #   lightning\n",
            "    #   lightning-utilities\n",
            "    #   matplotlib\n",
            "    #   optuna\n",
            "    #   pooch\n",
            "    #   pytorch-lightning\n",
            "    #   spacy\n",
            "    #   speechbrain\n",
            "    #   tensorboardx\n",
            "    #   thinc\n",
            "    #   torch-pitch-shift\n",
            "    #   torchmetrics\n",
            "    #   transformers\n",
            "    #   tts\n",
            "    #   weasel\u001b[0m\u001b[0m\n",
            "pandas==1.5.3\n",
            "    \u001b[32m# via\n",
            "    #   gradio\n",
            "    #   pyannote-database\n",
            "    #   pyannote-metrics\n",
            "    #   tts\u001b[0m\u001b[0m\n",
            "pillow==10.4.0\n",
            "    \u001b[32m# via\n",
            "    #   gradio\n",
            "    #   matplotlib\u001b[0m\u001b[0m\n",
            "platformdirs==4.2.2\n",
            "    \u001b[32m# via pooch\u001b[0m\u001b[0m\n",
            "pooch==1.8.2\n",
            "    \u001b[32m# via librosa\u001b[0m\u001b[0m\n",
            "preshed==3.0.9\n",
            "    \u001b[32m# via\n",
            "    #   spacy\n",
            "    #   thinc\u001b[0m\u001b[0m\n",
            "primepy==1.3\n",
            "    \u001b[32m# via torch-pitch-shift\u001b[0m\u001b[0m\n",
            "protobuf==4.25.4\n",
            "    \u001b[32m# via\n",
            "    #   tensorboard\n",
            "    #   tensorboardx\u001b[0m\u001b[0m\n",
            "psutil==6.0.0\n",
            "    \u001b[32m# via trainer\u001b[0m\u001b[0m\n",
            "pyannote-audio==3.2.0\n",
            "    \u001b[32m# via\n",
            "    #   -r /content/reqs.txt\n",
            "    #   brouhaha\u001b[0m\u001b[0m\n",
            "pyannote-core==5.0.0\n",
            "    \u001b[32m# via\n",
            "    #   pyannote-audio\n",
            "    #   pyannote-database\n",
            "    #   pyannote-metrics\n",
            "    #   pyannote-pipeline\u001b[0m\u001b[0m\n",
            "pyannote-database==5.1.0\n",
            "    \u001b[32m# via\n",
            "    #   pyannote-audio\n",
            "    #   pyannote-metrics\n",
            "    #   pyannote-pipeline\u001b[0m\u001b[0m\n",
            "pyannote-metrics==3.2.1\n",
            "    \u001b[32m# via pyannote-audio\u001b[0m\u001b[0m\n",
            "pyannote-pipeline==3.0.1\n",
            "    \u001b[32m# via pyannote-audio\u001b[0m\u001b[0m\n",
            "pycparser==2.22\n",
            "    \u001b[32m# via cffi\u001b[0m\u001b[0m\n",
            "pydantic==2.8.2\n",
            "    \u001b[32m# via\n",
            "    #   confection\n",
            "    #   fastapi\n",
            "    #   gradio\n",
            "    #   groq\n",
            "    #   langchain-core\n",
            "    #   langsmith\n",
            "    #   spacy\n",
            "    #   thinc\n",
            "    #   weasel\u001b[0m\u001b[0m\n",
            "pydantic-core==2.20.1\n",
            "    \u001b[32m# via pydantic\u001b[0m\u001b[0m\n",
            "pydub==0.25.1\n",
            "    \u001b[32m# via gradio\u001b[0m\u001b[0m\n",
            "pygments==2.18.0\n",
            "    \u001b[32m# via rich\u001b[0m\u001b[0m\n",
            "pynndescent==0.5.13\n",
            "    \u001b[32m# via umap-learn\u001b[0m\u001b[0m\n",
            "pyparsing==3.1.2\n",
            "    \u001b[32m# via matplotlib\u001b[0m\u001b[0m\n",
            "pypinyin==0.52.0\n",
            "    \u001b[32m# via tts\u001b[0m\u001b[0m\n",
            "pysbd==0.3.4\n",
            "    \u001b[32m# via tts\u001b[0m\u001b[0m\n",
            "python-crfsuite==0.9.10\n",
            "    \u001b[32m# via gruut\u001b[0m\u001b[0m\n",
            "python-dateutil==2.9.0.post0\n",
            "    \u001b[32m# via\n",
            "    #   dateparser\n",
            "    #   matplotlib\n",
            "    #   pandas\u001b[0m\u001b[0m\n",
            "python-multipart==0.0.9\n",
            "    \u001b[32m# via gradio\u001b[0m\u001b[0m\n",
            "pytorch-lightning==2.3.3\n",
            "    \u001b[32m# via lightning\u001b[0m\u001b[0m\n",
            "pytorch-metric-learning==2.6.0\n",
            "    \u001b[32m# via pyannote-audio\u001b[0m\u001b[0m\n",
            "pytz==2024.1\n",
            "    \u001b[32m# via\n",
            "    #   dateparser\n",
            "    #   pandas\u001b[0m\u001b[0m\n",
            "pyyaml==6.0.1\n",
            "    \u001b[32m# via\n",
            "    #   gradio\n",
            "    #   huggingface-hub\n",
            "    #   hyperpyyaml\n",
            "    #   langchain-core\n",
            "    #   lightning\n",
            "    #   omegaconf\n",
            "    #   optuna\n",
            "    #   pyannote-database\n",
            "    #   pyannote-pipeline\n",
            "    #   pytorch-lightning\n",
            "    #   transformers\n",
            "    #   tts\u001b[0m\u001b[0m\n",
            "regex==2024.7.24\n",
            "    \u001b[32m# via\n",
            "    #   dateparser\n",
            "    #   nltk\n",
            "    #   transformers\u001b[0m\u001b[0m\n",
            "requests==2.32.3\n",
            "    \u001b[32m# via\n",
            "    #   huggingface-hub\n",
            "    #   langsmith\n",
            "    #   pooch\n",
            "    #   spacy\n",
            "    #   transformers\n",
            "    #   weasel\u001b[0m\u001b[0m\n",
            "rich==13.7.1\n",
            "    \u001b[32m# via\n",
            "    #   pyannote-audio\n",
            "    #   typer\u001b[0m\u001b[0m\n",
            "ruamel-yaml==0.18.6\n",
            "    \u001b[32m# via hyperpyyaml\u001b[0m\u001b[0m\n",
            "ruamel-yaml-clib==0.2.8\n",
            "    \u001b[32m# via ruamel-yaml\u001b[0m\u001b[0m\n",
            "ruff==0.5.6\n",
            "    \u001b[32m# via gradio\u001b[0m\u001b[0m\n",
            "safetensors==0.4.4\n",
            "    \u001b[32m# via transformers\u001b[0m\u001b[0m\n",
            "scikit-learn==1.5.1\n",
            "    \u001b[32m# via\n",
            "    #   librosa\n",
            "    #   pyannote-metrics\n",
            "    #   pyannote-pipeline\n",
            "    #   pynndescent\n",
            "    #   pytorch-metric-learning\n",
            "    #   tts\n",
            "    #   umap-learn\u001b[0m\u001b[0m\n",
            "scipy==1.11.4\n",
            "    \u001b[32m# via\n",
            "    #   librosa\n",
            "    #   pyannote-core\n",
            "    #   pyannote-metrics\n",
            "    #   pynndescent\n",
            "    #   scikit-learn\n",
            "    #   speechbrain\n",
            "    #   tts\n",
            "    #   umap-learn\u001b[0m\u001b[0m\n",
            "semantic-version==2.10.0\n",
            "    \u001b[32m# via gradio\u001b[0m\u001b[0m\n",
            "semver==3.0.2\n",
            "    \u001b[32m# via pyannote-audio\u001b[0m\u001b[0m\n",
            "sentencepiece==0.2.0\n",
            "    \u001b[32m# via speechbrain\u001b[0m\u001b[0m\n",
            "shellingham==1.5.4\n",
            "    \u001b[32m# via typer\u001b[0m\u001b[0m\n",
            "six==1.16.0\n",
            "    \u001b[32m# via\n",
            "    #   jsonlines\n",
            "    #   python-dateutil\n",
            "    #   tensorboard\u001b[0m\u001b[0m\n",
            "smart-open==7.0.4\n",
            "    \u001b[32m# via weasel\u001b[0m\u001b[0m\n",
            "sniffio==1.3.1\n",
            "    \u001b[32m# via\n",
            "    #   anyio\n",
            "    #   groq\n",
            "    #   httpx\u001b[0m\u001b[0m\n",
            "sortedcontainers==2.4.0\n",
            "    \u001b[32m# via pyannote-core\u001b[0m\u001b[0m\n",
            "soundfile==0.12.1\n",
            "    \u001b[32m# via\n",
            "    #   librosa\n",
            "    #   pyannote-audio\n",
            "    #   trainer\n",
            "    #   tts\u001b[0m\u001b[0m\n",
            "soxr==0.4.0\n",
            "    \u001b[32m# via librosa\u001b[0m\u001b[0m\n",
            "spacy[ja]==3.7.5\n",
            "    \u001b[32m# via tts\u001b[0m\u001b[0m\n",
            "spacy-legacy==3.0.12\n",
            "    \u001b[32m# via spacy\u001b[0m\u001b[0m\n",
            "spacy-loggers==1.0.5\n",
            "    \u001b[32m# via spacy\u001b[0m\u001b[0m\n",
            "speechbrain==1.0.0\n",
            "    \u001b[32m# via pyannote-audio\u001b[0m\u001b[0m\n",
            "sqlalchemy==2.0.32\n",
            "    \u001b[32m# via\n",
            "    #   alembic\n",
            "    #   optuna\u001b[0m\u001b[0m\n",
            "srsly==2.4.8\n",
            "    \u001b[32m# via\n",
            "    #   confection\n",
            "    #   spacy\n",
            "    #   thinc\n",
            "    #   weasel\u001b[0m\u001b[0m\n",
            "starlette==0.37.2\n",
            "    \u001b[32m# via fastapi\u001b[0m\u001b[0m\n",
            "sudachidict-core==20240716\n",
            "    \u001b[32m# via spacy\u001b[0m\u001b[0m\n",
            "sudachipy==0.6.8\n",
            "    \u001b[32m# via\n",
            "    #   spacy\n",
            "    #   sudachidict-core\u001b[0m\u001b[0m\n",
            "sympy==1.13.1\n",
            "    \u001b[32m# via\n",
            "    #   pyannote-metrics\n",
            "    #   torch\u001b[0m\u001b[0m\n",
            "tabulate==0.9.0\n",
            "    \u001b[32m# via pyannote-metrics\u001b[0m\u001b[0m\n",
            "tenacity==8.5.0\n",
            "    \u001b[32m# via langchain-core\u001b[0m\u001b[0m\n",
            "tensorboard==2.17.0\n",
            "    \u001b[32m# via trainer\u001b[0m\u001b[0m\n",
            "tensorboard-data-server==0.7.2\n",
            "    \u001b[32m# via tensorboard\u001b[0m\u001b[0m\n",
            "tensorboardx==2.6.2.2\n",
            "    \u001b[32m# via pyannote-audio\u001b[0m\u001b[0m\n",
            "thinc==8.2.5\n",
            "    \u001b[32m# via spacy\u001b[0m\u001b[0m\n",
            "threadpoolctl==3.5.0\n",
            "    \u001b[32m# via scikit-learn\u001b[0m\u001b[0m\n",
            "tokenizers==0.19.1\n",
            "    \u001b[32m# via transformers\u001b[0m\u001b[0m\n",
            "tomlkit==0.12.0\n",
            "    \u001b[32m# via gradio\u001b[0m\u001b[0m\n",
            "torch==2.4.0\n",
            "    \u001b[32m# via\n",
            "    #   -r /content/reqs.txt\n",
            "    #   asteroid-filterbanks\n",
            "    #   encodec\n",
            "    #   julius\n",
            "    #   lightning\n",
            "    #   pyannote-audio\n",
            "    #   pytorch-lightning\n",
            "    #   pytorch-metric-learning\n",
            "    #   speechbrain\n",
            "    #   torch-audiomentations\n",
            "    #   torch-pitch-shift\n",
            "    #   torchaudio\n",
            "    #   torchmetrics\n",
            "    #   trainer\n",
            "    #   tts\u001b[0m\u001b[0m\n",
            "torch-audiomentations==0.11.1\n",
            "    \u001b[32m# via pyannote-audio\u001b[0m\u001b[0m\n",
            "torch-pitch-shift==1.2.4\n",
            "    \u001b[32m# via torch-audiomentations\u001b[0m\u001b[0m\n",
            "torchaudio==2.4.0\n",
            "    \u001b[32m# via\n",
            "    #   encodec\n",
            "    #   pyannote-audio\n",
            "    #   speechbrain\n",
            "    #   torch-audiomentations\n",
            "    #   torch-pitch-shift\n",
            "    #   tts\u001b[0m\u001b[0m\n",
            "torchmetrics==1.4.1\n",
            "    \u001b[32m# via\n",
            "    #   lightning\n",
            "    #   pyannote-audio\n",
            "    #   pytorch-lightning\u001b[0m\u001b[0m\n",
            "tqdm==4.66.5\n",
            "    \u001b[32m# via\n",
            "    #   huggingface-hub\n",
            "    #   lightning\n",
            "    #   nltk\n",
            "    #   optuna\n",
            "    #   pyannote-pipeline\n",
            "    #   pytorch-lightning\n",
            "    #   pytorch-metric-learning\n",
            "    #   spacy\n",
            "    #   speechbrain\n",
            "    #   transformers\n",
            "    #   tts\n",
            "    #   umap-learn\u001b[0m\u001b[0m\n",
            "trainer==0.0.36\n",
            "    \u001b[32m# via tts\u001b[0m\u001b[0m\n",
            "transformers==4.43.4\n",
            "    \u001b[32m# via\n",
            "    #   -r /content/reqs.txt\n",
            "    #   tts\u001b[0m\u001b[0m\n",
            "triton==3.0.0\n",
            "    \u001b[32m# via torch\u001b[0m\u001b[0m\n",
            "tts==0.22.0\n",
            "    \u001b[32m# via -r /content/reqs.txt\u001b[0m\u001b[0m\n",
            "typeguard==4.3.0\n",
            "    \u001b[32m# via inflect\u001b[0m\u001b[0m\n",
            "typer==0.12.3\n",
            "    \u001b[32m# via\n",
            "    #   gradio\n",
            "    #   pyannote-database\n",
            "    #   spacy\n",
            "    #   weasel\u001b[0m\u001b[0m\n",
            "typing-extensions==4.12.2\n",
            "    \u001b[32m# via\n",
            "    #   alembic\n",
            "    #   anyio\n",
            "    #   asteroid-filterbanks\n",
            "    #   cloudpathlib\n",
            "    #   fastapi\n",
            "    #   gradio\n",
            "    #   gradio-client\n",
            "    #   groq\n",
            "    #   huggingface-hub\n",
            "    #   langchain-core\n",
            "    #   librosa\n",
            "    #   lightning\n",
            "    #   lightning-utilities\n",
            "    #   pyannote-core\n",
            "    #   pydantic\n",
            "    #   pydantic-core\n",
            "    #   pytorch-lightning\n",
            "    #   sqlalchemy\n",
            "    #   torch\n",
            "    #   typeguard\n",
            "    #   typer\n",
            "    #   uvicorn\u001b[0m\u001b[0m\n",
            "tzlocal==5.2\n",
            "    \u001b[32m# via dateparser\u001b[0m\u001b[0m\n",
            "umap-learn==0.5.6\n",
            "    \u001b[32m# via tts\u001b[0m\u001b[0m\n",
            "unidecode==1.3.8\n",
            "    \u001b[32m# via tts\u001b[0m\u001b[0m\n",
            "urllib3==2.2.2\n",
            "    \u001b[32m# via\n",
            "    #   gradio\n",
            "    #   requests\u001b[0m\u001b[0m\n",
            "uvicorn==0.30.5\n",
            "    \u001b[32m# via gradio\u001b[0m\u001b[0m\n",
            "wasabi==1.1.3\n",
            "    \u001b[32m# via\n",
            "    #   spacy\n",
            "    #   thinc\n",
            "    #   weasel\u001b[0m\u001b[0m\n",
            "wave==0.0.2\n",
            "    \u001b[32m# via -r /content/reqs.txt\u001b[0m\u001b[0m\n",
            "weasel==0.4.1\n",
            "    \u001b[32m# via spacy\u001b[0m\u001b[0m\n",
            "websockets==12.0\n",
            "    \u001b[32m# via gradio-client\u001b[0m\u001b[0m\n",
            "werkzeug==3.0.3\n",
            "    \u001b[32m# via\n",
            "    #   flask\n",
            "    #   tensorboard\u001b[0m\u001b[0m\n",
            "wrapt==1.16.0\n",
            "    \u001b[32m# via smart-open\u001b[0m\u001b[0m\n",
            "yarl==1.9.4\n",
            "    \u001b[32m# via aiohttp\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[32m# The following packages are considered to be unsafe in a requirements file:\u001b[0m\u001b[0m\n",
            "\u001b[32m# setuptools\u001b[0m\u001b[0m\n",
            "Collecting brouhaha@ https://github.com/marianne-m/brouhaha-vad/archive/main.zip (from -r requirements.txt (line 53))\n",
            "  Downloading https://github.com/marianne-m/brouhaha-vad/archive/main.zip\n",
            "\u001b[2K     \u001b[32m/\u001b[0m \u001b[32m19.5 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m \u001b[33m0:00:03\u001b[0m"
          ]
        }
      ],
      "source": [
        "#@title Install Dependencies\n",
        "!pip-compile /content/reqs.txt --resolver=backtracking -o requirements.txt\n",
        "!pip install -r requirements.txt\n",
        "!pip install langchain_groq transformers torch TTS gradio wave pyannote-audio https://github.com/marianne-m/brouhaha-vad/archive/main.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "vYBC8LNwpsMC"
      },
      "outputs": [],
      "source": [
        "#@title Set Up TTS Model\n",
        "import torch\n",
        "from TTS.api import TTS\n",
        "import os\n",
        "import sys\n",
        "\n",
        "os.environ['COQUI_TOS_AGREED'] = '1'\n",
        "device = 'cuda'\n",
        "\n",
        "\n",
        "tts = TTS('tts_models/multilingual/multi-dataset/xtts_v2').to(device)\n",
        "\n",
        "def clone(text, audio, index):\n",
        "    tts.tts_to_file(text=text, speaker_wav=audio, language='en', file_path=f'/content/output{index}.wav')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "bTwDcl-Xt5ys"
      },
      "outputs": [],
      "source": [
        "#@title Set Up LLM & STT Model & Some other useful functions\n",
        "\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from google.colab import userdata\n",
        "import os\n",
        "GROQ_API_KEY = userdata.get('GROQ_API_KEY')\n",
        "os.environ['GROQ_API_KEY'] = GROQ_API_KEY\n",
        "chat_llama = ChatGroq(groq_api_key=GROQ_API_KEY,model=\"llama3-70b-8192\",verbose = True,temperature=0)\n",
        "chat_mixtral = ChatGroq(groq_api_key=GROQ_API_KEY,model=\"mixtral-8x7b-32768\",verbose = True,temperature=0)\n",
        "import time\n",
        "\n",
        "def handle_errors(error):\n",
        "    error_string = error.args[0]\n",
        "    json_start = error_string.find(\"{\")\n",
        "    json_end = error_string.rfind(\"}\")\n",
        "    json_string = error_string[json_start:json_end + 1]\n",
        "    print(json_string)\n",
        "    response = None\n",
        "\n",
        "    if \"rate_limit_exceeded\" in json_string:\n",
        "      delay = json_string[json_string.find(\"try again in \")+13:]\n",
        "      delay = delay[:delay.find(\"s\")+1]\n",
        "      if \"ms\" in delay:\n",
        "        seconds = float(delay.replace(\"ms\",\"\"))\n",
        "        seconds = seconds/100\n",
        "        seconds = int(seconds)\n",
        "\n",
        "      elif \"m\" in delay:\n",
        "        minutes = delay[:delay.find(\"m\")]\n",
        "        minutes = int(minutes)\n",
        "        seconds = minutes * 60\n",
        "        print(delay)\n",
        "        plus = delay[delay.find(\"m\")+1:delay.find(\"s\")]\n",
        "        plus = plus[:plus.find(\".\")]\n",
        "        plus = int(plus) + 1\n",
        "        seconds = seconds + plus\n",
        "\n",
        "      else:\n",
        "        seconds = delay[:delay.find(\".\")]\n",
        "        seconds = int(seconds)\n",
        "      seconds = seconds + 20\n",
        "      print(\"Rate Limited: Waiting for \"+str(seconds) + \" seconds\")\n",
        "      time.sleep(seconds)\n",
        "\n",
        "\n",
        "    if \"failed_generation\" in json_string:\n",
        "        attempt = json_string[json_string.rfind(\"'json_validate_failed':\")+23]\n",
        "        attempt = attempt[:len(attempt)-2]\n",
        "        print(attempt)\n",
        "        system_message = \"\"\"Your task is to transform an invalid JSON into a valid JSON object. You will receive JSON data that contains formatting errors. Your goal is to correct all formatting errors and respond with a valid JSON object.\n",
        "\n",
        "Requirements:\n",
        "1. Identify and correct all syntax errors.\n",
        "2. Ensure the output is a valid JSON object that passes standard JSON validation.\n",
        "\n",
        "Expected Output:\n",
        "- A valid JSON object.\n",
        "\"\"\"\n",
        "        user_message = \"\"\"Correct the following JSON to make it valid. Return only the corrected JSON object. Here is the invalid JSON you need to correct:\n",
        "{attempt}\"\"\"\n",
        "\n",
        "        messages = [(\"system\",system_message),(\"user\",user_message)]\n",
        "        prompt = ChatPromptTemplate.from_messages(messages)\n",
        "        json_chat = chat_llama.with_structured_output(SceneSchema2,method=\"json_mode\")\n",
        "      # error_messages = messages\n",
        "      # error_messages.append((\"assistant\",error))\n",
        "      # error_messages.append((\"user\",\"\"\"Try again, correcting the errors of your last attempt. MAKE SURE to generate the Location, Description and Lines as VALID JSON this time.\"\"\"))\n",
        "      # prompt = ChatPromptTemplate.from_messages(error_messages)\n",
        "        chain = prompt | json_chat\n",
        "        try:\n",
        "          response = chain.invoke({\"attempt\":attempt})\n",
        "        except Exception as e:\n",
        "          error_string = error.args[0]\n",
        "          print(error_string)\n",
        "          json_start = error_string.find(\"{\")\n",
        "          json_end = error_string.rfind(\"}\")\n",
        "          json_string = error_string[json_start:json_end + 1]\n",
        "    return response\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "import re\n",
        "alphabets= \"([A-Za-z])\"\n",
        "prefixes = \"(Mr|St|Mrs|Ms|Dr)[.]\"\n",
        "suffixes = \"(Inc|Ltd|Jr|Sr|Co)\"\n",
        "starters = \"(Mr|Mrs|Ms|Dr|Prof|Capt|Cpt|Lt|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\n",
        "acronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\n",
        "websites = \"[.](com|net|org|io|gov|edu|me)\"\n",
        "digits = \"([0-9])\"\n",
        "multiple_dots = r'\\.{2,}'\n",
        "\n",
        "def split_into_sentences(text: str) -> list[str]:\n",
        "    \"\"\"\n",
        "    Split the text into sentences.\n",
        "\n",
        "    If the text contains substrings \"<prd>\" or \"<stop>\", they would lead\n",
        "    to incorrect splitting because they are used as markers for splitting.\n",
        "\n",
        "    :param text: text to be split into sentences\n",
        "    :type text: str\n",
        "\n",
        "    :return: list of sentences\n",
        "    :rtype: list[str]\n",
        "    \"\"\"\n",
        "    text = \" \" + text + \"  \"\n",
        "    text = text.replace(\"\\n\",\" \")\n",
        "    text = re.sub(prefixes,\"\\\\1<prd>\",text)\n",
        "    text = re.sub(websites,\"<prd>\\\\1\",text)\n",
        "    text = re.sub(digits + \"[.]\" + digits,\"\\\\1<prd>\\\\2\",text)\n",
        "    text = re.sub(multiple_dots, lambda match: \"<prd>\" * len(match.group(0)) + \"<stop>\", text)\n",
        "    if \"Ph.D\" in text: text = text.replace(\"Ph.D.\",\"Ph<prd>D<prd>\")\n",
        "    text = re.sub(\"\\s\" + alphabets + \"[.] \",\" \\\\1<prd> \",text)\n",
        "    text = re.sub(acronyms+\" \"+starters,\"\\\\1<stop> \\\\2\",text)\n",
        "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\\\\3<prd>\",text)\n",
        "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\",text)\n",
        "    text = re.sub(\" \"+suffixes+\"[.] \"+starters,\" \\\\1<stop> \\\\2\",text)\n",
        "    text = re.sub(\" \"+suffixes+\"[.]\",\" \\\\1<prd>\",text)\n",
        "    text = re.sub(\" \" + alphabets + \"[.]\",\" \\\\1<prd>\",text)\n",
        "    if \"”\" in text: text = text.replace(\".”\",\"”.\")\n",
        "    if \"\\\"\" in text: text = text.replace(\".\\\"\",\"\\\".\")\n",
        "    if \"!\" in text: text = text.replace(\"!\\\"\",\"\\\"!\")\n",
        "    if \"?\" in text: text = text.replace(\"?\\\"\",\"\\\"?\")\n",
        "    text = text.replace(\".\",\".<stop>\")\n",
        "    text = text.replace(\"?\",\"?<stop>\")\n",
        "    text = text.replace(\"!\",\"!<stop>\")\n",
        "    text = text.replace(\"<prd>\",\".\")\n",
        "    sentences = text.split(\"<stop>\")\n",
        "    sentences = [s.strip() for s in sentences]\n",
        "    if sentences and not sentences[-1]: sentences = sentences[:-1]\n",
        "    return sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fXH-aL39rzFd"
      },
      "outputs": [],
      "source": [
        "#@title Set Up Speech Detection Model\n",
        "\n",
        "from pyannote.audio import Model\n",
        "model = Model.from_pretrained(\"pyannote/brouhaha\",\n",
        "                              use_auth_token=\"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\")\n",
        "\n",
        "# apply model\n",
        "from pyannote.audio import Inference\n",
        "inference = Inference(model)\n",
        "output = inference(\"/content/drive/MyDrive/Storytime/Repository/VOICES/boy.wav\")\n",
        "\n",
        "# iterate over each frame\n",
        "for frame, (vad, snr, c50) in output:\n",
        "    t = frame.middle\n",
        "    print(f\"{t:8.3f} vad={100*vad:.0f}% snr={snr:.0f} c50={c50:.0f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run as a Gradio App LIVE STREAMING\n",
        "\n",
        "import gradio as gr\n",
        "from IPython.display import Audio, display\n",
        "import numpy as np\n",
        "import wave\n",
        "from scipy.fft import fft\n",
        "import scipy.io.wavfile as wav\n",
        "from transformers import pipeline\n",
        "import time\n",
        "import random\n",
        "import os\n",
        "import locale\n",
        "import uuid\n",
        "\n",
        "os.environ['LC_ALL'] = 'en_US.UTF-8'\n",
        "os.environ['LANG'] = 'en_US.UTF-8'\n",
        "locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')\n",
        "\n",
        "transcriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base.en\", device=\"cuda\")\n",
        "\n",
        "def has_speech_spectral(chunk, min_power, sample_rate=44100, freq_threshold=800):\n",
        "\n",
        "    # Calculate the Fast Fourier Transform (FFT) of the chunk\n",
        "    fft_data = fft(chunk)\n",
        "\n",
        "    # Calculate the absolute value (magnitude) of the complex FFT results\n",
        "    magnitude = np.abs(fft_data)\n",
        "\n",
        "    # Calculate the average power above the frequency threshold\n",
        "    avg_power_above = np.mean(magnitude[int(freq_threshold * len(magnitude) / sample_rate):])\n",
        "    print(avg_power_above)\n",
        "    # Return True if average power is significant\n",
        "    return avg_power_above > min_power\n",
        "\n",
        "def chat_response(message):\n",
        "    prompt = ChatPromptTemplate.from_messages(message)\n",
        "    chain = prompt | chat_llama\n",
        "    response = \"\"\n",
        "    while response == \"\":\n",
        "      try:\n",
        "        response = chain.invoke({})\n",
        "      except Exception as e:\n",
        "        r = handle_errors(e)\n",
        "        if r!=None:\n",
        "          response=r\n",
        "    return response.content\n",
        "\n",
        "def save_audio_chunks(audio, start_time, not_speech_counter, audio_chunk):\n",
        "\n",
        "    # Make sure the audio chunk has the right number of channels (1) for speech recognition\n",
        "    if len(audio[1].shape) == 2 and audio[1].shape[1] == 2:\n",
        "      audio = (audio[0],np.ascontiguousarray(audio[1].mean(axis=1), dtype=np.int16))\n",
        "\n",
        "    if str(audio[1]) != str(audio_chunk):\n",
        "    # Write the new audio chunk to a wav file\n",
        "      with wave.open(\"speech.wav\", 'wb') as wav_file:\n",
        "        wav_file.setnchannels(1)\n",
        "        wav_file.setsampwidth(2)\n",
        "        wav_file.setframerate(audio[0])\n",
        "        wav_file.writeframesraw(audio[1])\n",
        "\n",
        "    # Check if the new audio chunk contains speech\n",
        "      output = inference(\"speech.wav\")\n",
        "      speech = False\n",
        "      speech_counter = 0\n",
        "      for frame, (vad, snr, c50) in output:\n",
        "        t = frame.middle\n",
        "        if vad > 0.95 and snr > 15:\n",
        "          print(f\"{t:8.3f} vad={100*vad:.0f}% snr={snr:.0f} c50={c50:.0f}\")\n",
        "          speech_counter += 1\n",
        "          if speech_counter > 3:\n",
        "            if has_speech_spectral(audio[1], 5000):\n",
        "               speech = True\n",
        "               break\n",
        "\n",
        "    # If the audio chunk contains speech add it to the audio_chunk state\n",
        "      if speech:\n",
        "        print(\"saving speech\")\n",
        "        start_time = time.time()\n",
        "        not_speech_counter = 0\n",
        "        sound = audio[1].astype(np.float32)\n",
        "        sound /= np.max(np.abs(sound))\n",
        "        if not audio_chunk.any():\n",
        "           audio_chunk = sound\n",
        "        else:\n",
        "           i=0\n",
        "           total_length = audio_chunk.shape[0] + sound.shape[0]\n",
        "           result = np.empty(total_length, dtype=np.float32)\n",
        "           arrays = [audio_chunk, sound]\n",
        "           for arr in arrays:\n",
        "              result[i:i + arr.shape[0]] = arr\n",
        "              i += arr.shape[0]\n",
        "           audio_chunk = result\n",
        "        yield start_time, not_speech_counter, audio_chunk\n",
        "\n",
        "      else:\n",
        "         not_speech_counter += 1\n",
        "         yield start_time, not_speech_counter, audio_chunk\n",
        "\n",
        "    else:\n",
        "      yield start_time, not_speech_counter, audio_chunk\n",
        "\n",
        "def get_agent_response(response,not_speech_counter,start_time,audio_chunk,user_message,last_user_message,chat_history,response_obselete):\n",
        "      # transcribe: the user's message if they have stopped speaking\n",
        "\n",
        "      if audio_chunk.any():\n",
        "          print(\"START: \"+ str(time.time() - start_time))\n",
        "          print(\"NOT: \"+ str(not_speech_counter))\n",
        "      if (not_speech_counter > 1 or time.time() - start_time > 2) and audio_chunk.any():\n",
        "          #try to avoid transcribing same chunk twice\n",
        "          ut = transcriber({\"sampling_rate\": 48000, \"raw\": audio_chunk})\n",
        "          print(\"TRANSCRIBED: \" + str(ut))\n",
        "          if not user_message.endswith(ut[\"text\"]):\n",
        "             user_message = user_message + \" \" + ut[\"text\"]\n",
        "             audio_chunk = np.empty(0, dtype=np.float32)\n",
        "\n",
        "      # get a response from AI chatbot\n",
        "      if user_message != \"\" and user_message != last_user_message:\n",
        "          print(\"message: \"+ user_message)\n",
        "          last_user_message = user_message\n",
        "          mock_chat_history = chat_history\n",
        "          mock_chat_history.append((\"user\", user_message))\n",
        "          response = chat_response(mock_chat_history)\n",
        "          print(response)\n",
        "          response_obselete = True\n",
        "\n",
        "      return response, not_speech_counter, start_time, audio_chunk, user_message, last_user_message, response_obselete\n",
        "\n",
        "def process_response(response,last_response,response_obselete,sentences,number_of_sentences,process_index,run_id):\n",
        "      if response != \"\" and response != None and response != last_response:\n",
        "           last_response = response\n",
        "           sentences = split_into_sentences(response)\n",
        "           response = \"\"\n",
        "           user_message = \"\"\n",
        "           response_obselete = False\n",
        "           i=0\n",
        "           number_of_sentences = len(sentences)\n",
        "           for sentence in sentences:\n",
        "             sentence = sentence.replace(\"\\\"\",\"\")\n",
        "             process_index = i\n",
        "             pattern = r'[A-Za-z0-9]'\n",
        "             match = re.search(pattern, sentence)\n",
        "             is_match = match is not None\n",
        "             if not response_obselete and is_match:\n",
        "                clone(sentence, \"/content/drive/MyDrive/Storytime/Repository/VOICES/man19.wav\", i)\n",
        "                !mv /content/output{str(i)}.wav /content/{run_id}/output{str(i)}.wav\n",
        "                yield response,last_response,response_obselete,sentences,number_of_sentences,user_message,process_index\n",
        "             elif not is_match:\n",
        "                sentences.pop(i)\n",
        "                number_of_sentences = len(sentences)\n",
        "                i-=1\n",
        "             elif response_obselete:\n",
        "                yield response,last_response,response_obselete,sentences,number_of_sentences,user_message,process_index\n",
        "                break\n",
        "             i+=1\n",
        "\n",
        "def interrupt(audio):\n",
        "  audio = None\n",
        "  return audio, 0\n",
        "\n",
        "def play_first(run_id, play_index):\n",
        "        if os.path.exists(f\"/content/{run_id}/output0.wav\"):\n",
        "          with wave.open(f\"/content/{run_id}/output0.wav\", 'rb') as wav_file:\n",
        "            frames = wav_file.getnframes()\n",
        "            rate = wav_file.getframerate()\n",
        "            duration = frames / float(rate)\n",
        "          play_index = 1\n",
        "          yield f\"/content/{run_id}/output0.wav\", play_index\n",
        "          !rm -rf /content/{run_id}/output0.wav\n",
        "          time.sleep(duration+1)\n",
        "\n",
        "def play_next(run_id,play_index,number_of_sentences):\n",
        "        print(\"playindex: \"+str(play_index))\n",
        "        print(\"nos: \"+str(number_of_sentences))\n",
        "        if play_index < number_of_sentences:\n",
        "          while not os.path.exists(f\"/content/{run_id}/output{str(play_index)}.wav\"):\n",
        "            time.sleep(0.5)\n",
        "          next = play_index + 1\n",
        "          yield f\"/content/{run_id}/output{str(play_index)}.wav\", next\n",
        "          !rm -rf /content/{run_id}/output{str(play_index)}.wav\n",
        "        else:\n",
        "          play_index = 0\n",
        "          yield None, play_index\n",
        "\n",
        "def add_user_message(user_message, chat_history, sentences, audio_chunk):\n",
        "      if len(sentences) > 0:\n",
        "        chat_history.append((\"user\", user_message))\n",
        "        chat_history.append((\"assistant\", sentences[0]))\n",
        "      sentences = []\n",
        "      user_message = \"\"\n",
        "      audio_chunk = np.empty(0, dtype=np.float32)\n",
        "      return user_message, chat_history, sentences, audio_chunk\n",
        "\n",
        "def add_assistant_message(sentences, chat_history, play_index):\n",
        "   if len(sentences) > play_index:\n",
        "      msg = chat_history[-1][1] + \" \" + sentences[play_index]\n",
        "      msg = msg.strip()\n",
        "      chat_history[-1] = (\"assistant\", msg)\n",
        "   return chat_history\n",
        "\n",
        "def system_prompt_custom(Name,Gender,Age,run_id,chat_history,ready):\n",
        "      pronoun = \"she\" if Gender == \"Girl\" else \"he\"\n",
        "\n",
        "      system_message = f\"\"\"You are a master story teller who tells the most incredibly engaging and entertaining customised stories for children.\n",
        "\n",
        "The name of the child you will tell the story is a {Gender} named {Name} who is {Age} years old.\n",
        "\n",
        "You will be expected to tailor the story to {Name} and {pronoun} unique individual interests and likes.\n",
        "\n",
        "You will be expected to tell stories in a conversational style, involving {Name} in the definition of and development of the story.\n",
        "\n",
        "Keep your responses short and snappy. {Name} is {Age} years old, make sure to adapt your narrative style to {pronoun} age group. You are limited to asking one question per response. Remember to keep the story fun and engaging at all times!\n",
        "\"\"\"\n",
        "      chat_history.append((\"system\", system_message))\n",
        "      run_id = uuid.uuid4()\n",
        "      print(run_id)\n",
        "      welcome_message = f\"Hi {Name}, I'm so excited to make a story just for you! To get started, just press the 'Record' button and tell me about some things you like!\"\n",
        "      clone(welcome_message, \"/content/drive/MyDrive/Storytime/Repository/VOICES/man19.wav\", 99999)\n",
        "      os.makedirs(str(run_id))\n",
        "      !mv /content/output99999.wav /content/{run_id}/output99999.wav\n",
        "      yield f\"/content/{run_id}/output99999.wav\", chat_history, f\"😄😄😄 STARTING VOICE CHAT with {Name.upper()}! 😄😄😄\", run_id\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# Welcome to the Story Time App!\")\n",
        "    gr.Markdown(\"### Instructions:\")\n",
        "    gr.Markdown(\"1. Change the Name, Gender and Age to suit your needs and click 'Submit'.\")\n",
        "    gr.Markdown(\"2. Click 'Record' and start talking to the Story Teller live in real time. Create an amazing story together!\")\n",
        "    gr.Markdown(\"Tip: If the Story Teller stops talking, just say something and he will start again.\")\n",
        "    Name = gr.Textbox(label=\"Name\", value=\"Billy\")\n",
        "    Gender = gr.Radio(choices=[\"Boy\", \"Girl\"], label=\"Gender\", value=\"Boy\")\n",
        "    Age = gr.Slider(minimum=0, maximum=12, step=1, label=\"Age\", value=\"5\")\n",
        "    system_prompt = gr.Textbox(visible=False)\n",
        "    submit_button = gr.Button(\"Submit\")\n",
        "    ready = gr.Textbox()\n",
        "\n",
        "    mic_input = gr.Audio(sources=['microphone'],streaming=True)\n",
        "    agent_response = gr.Textbox(visible=False)\n",
        "    first_output = gr.Audio(type=\"filepath\",autoplay=True)\n",
        "    audio_output = gr.Audio(type=\"filepath\",autoplay=True)\n",
        "\n",
        "    run_id = gr.State()\n",
        "\n",
        "    chat_history = gr.State(value=[])\n",
        "    play_index = gr.State(value=0)\n",
        "    number_of_sentences = gr.State(value=0)\n",
        "    process_index = gr.State(value=0)\n",
        "    start_time = gr.State(value=0)\n",
        "    not_speech_counter = gr.State(value=0)\n",
        "    audio_chunk = gr.State(value=np.empty(0, dtype=np.float32))\n",
        "    user_message = gr.State(value=\"\")\n",
        "    last_response = gr.State(value=\"\")\n",
        "    last_user_message = gr.State(value=\"\")\n",
        "    response_obselete = gr.State(value=False)\n",
        "    sentences = gr.State(value=[])\n",
        "\n",
        "    submit_button.click(system_prompt_custom, inputs=[Name,Gender,Age,run_id,chat_history,ready], outputs=[first_output,chat_history,ready,run_id])\n",
        "\n",
        "    mic_input.change(fn=save_audio_chunks, inputs=[mic_input,start_time,not_speech_counter,audio_chunk], outputs=[start_time,not_speech_counter,audio_chunk])\n",
        "    ar = gr.Timer(value=1).tick(fn=get_agent_response,inputs=[agent_response,not_speech_counter,start_time,audio_chunk,user_message,last_user_message,chat_history,response_obselete],outputs=[agent_response,not_speech_counter,start_time,audio_chunk,user_message,last_user_message,response_obselete])\n",
        "    agent_response.change(fn=process_response,inputs=[agent_response,last_response,response_obselete,sentences,number_of_sentences,process_index,run_id],outputs=[agent_response,last_response,response_obselete,sentences,number_of_sentences,process_index])\n",
        "\n",
        "    try_play_first = gr.Timer(value=1).tick(fn=play_first,inputs=[run_id,play_index],outputs=[first_output,play_index], trigger_mode=\"once\")\n",
        "    gr.on(triggers=[first_output.stop,audio_output.stop],fn=play_next,inputs=[run_id,play_index,number_of_sentences],outputs=[audio_output,play_index])\n",
        "    gr.on(triggers=[first_output.play],fn=interrupt, inputs=[],outputs=[audio_output,process_index])\n",
        "    gr.on(triggers=[first_output.stop],fn=add_user_message, inputs=[user_message,chat_history,sentences,audio_chunk],outputs=[user_message,chat_history,sentences,audio_chunk])\n",
        "    gr.on(triggers=[audio_output.stop],fn=add_assistant_message, inputs=[sentences,chat_history, play_index],outputs=[chat_history])\n",
        "\n",
        "demo.queue()\n",
        "demo.launch(share=True,debug=True)"
      ],
      "metadata": {
        "id": "ioKbkcKy-583"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyNSZuY5C1CmSpUi9MRLnJx/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}